type Dataset;
type TrainData;
type TestData;
type List;
type Tuple;

def psb2 : Unit = native_import "psb2";
def textdistance : Unit = native_import "textdistance";

def load_dataset : (name:String) -> (nTrain:Int) -> (nTest:Int) -> Dataset = native "lambda s: lambda train: lambda test: psb2.fetch_examples('path/to/PSB2/datasets/', s, train, test, format='lists')";

def extract_train_data : (ds:Dataset) -> TrainData = native "lambda ds: ds[0]";

def unpack_train_data : (td:TrainData) -> Tuple = native "lambda td: list(map(list, zip(*td)))";

def get_input_list : (t:Tuple) -> List = native "lambda t: t[0]";

def get_output_list : (t:Tuple) -> List = native "lambda t: sum(t[1], [])";

def extract_test_data : (ds:Dataset) -> TestData = native "lambda ds: ds[1]";

def mean_absolute_error : (true_values : List) -> (expected_values : List) ->  Float = native "lambda t: lambda e: __import__('numpy').mean(__import__('numpy').abs(__import__('numpy').array(t) - __import__('numpy').array(e)))";

# add a refinement to make sure that the lists are all the same size
def calculate_list_errors : (true_values : List) -> (expected_values : List) ->  List =  native "lambda t: lambda e: [abs(p - r) for p, r in zip(t, e)]";

# maybe move this method to string lib
def String_distance : (str1 : String) -> (str2 : String) -> Float = native "lambda s1: lambda s2: __import__('textdistance').levenshtein(s1, s2)";

def calculate_str_list_errors : (true_values : List) -> (expected_values : List) ->  List =  native "lambda t: lambda e: [__import__('textdistance').levenshtein(p, r) for p, r in zip(t, e)]";

def join_string_list : (list: List) -> String = native "lambda xs: ' '.join(word.strip() for word in xs) ";

def get_bb_synth_values : (input : List) -> (f:(a: Float) ->( b:Float ) -> (c:Int) -> Float ) -> List = native " lambda inputs: lambda function: [function(x)(y)(z) for x, y, z in inputs]";

def get_dg_synth_values : (input : List) -> (f: (a:{n:Int | 1 <= n && n <= 10000}) ->( b:{m:Int | 1 <= m && m <= 10000} ) -> Float ) -> List = native " lambda inputs: lambda function: [function(x)(y) for x, y in inputs]";

def get_fb_synth_values : (input : List) -> (f: (a: Int) -> String ) -> List = native " lambda inputs: lambda function: [function(x) for x in inputs]";

def get_gcd_synth_values : (input : List) -> (f:(a: Int) -> (b: Int)->  Int ) -> List = native " lambda inputs: lambda function: [function(x)(y) for x,y in inputs]";

def get_mc_synth_values : (input : List) -> (f:(a: String) -> String ) -> List = native " lambda inputs: lambda function: [function(x) for x in inputs]";

def get_snowd_synth_values : (input : List) -> (f:(a: Int) ->( b:Float ) -> (c:Float) ->(d:Float)  -> Float ) -> List = native " lambda inputs: lambda function: [function(x)(y)(z)(w) for x, y, z, w in inputs]";

def get_sd_synth_values : (input : List) -> (f:(a: Int) -> String ) -> List = native " lambda inputs: lambda function: [function(x) for x in inputs]";

def get_tt_synth_values : (input : List) -> (f:(a: String) -> String ) -> List = native " lambda inputs: lambda function: [function(x) for x in inputs]";

#def train: TrainData = extract_train_data (load_dataset "gcd" 200 200);
#def input_list : List = get_input_list (unpack_train_data train);
#def expected_values : List = get_output_list (unpack_train_data train);
